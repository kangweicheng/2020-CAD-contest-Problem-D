DATA:
    fn: 'power.pkl' # timing.csv or power.csv
HYPERPARAMETER:
    LGBM:
        boosting_type: ['gbdt', 'dart', 'goss'] # 'gbdt', 'rf', 'dart', 'goss'
        objective: ['regression']
        metric: ['l1', 'l2']
        num_leaves: [31, 15]
        learning_rate: [0.01, 0.05, 0.1]
        feature_fraction: [0.041, 0.9]
        bagging_fraction: [0.331, 0.8]
        min_data_in_leaf: [80]
        min_sum_hessian_in_leaf: [10.0]
        bagging_freq: [5]
        verbose: [0]
        epoch: [100]
        seed: [44000]
SAVED:
    model_fn: 'saved/model.txt'
    output_dir: 'saved/power/'
DATALOADER:
    batch_size: 256
    shuffle: True
    val_split: 0
    num_worker: 8
MODEL:
    vocab_size: 32
    hidden_size: 64
    pad_length: 32
    use_function: True
    type: 'NN' # NN or LSTM
TRAINER:
    n_epochs: 50
    n_show_loss: 100